scale_x_continuous(labels = percent) + my.theme)
Plot.setting(ggplot(sentences, aes(pct.complete, pol)) +
ylab("Sentiment (sentence-level polarity)") +
ggtitle(ff.A[[9]]$meta$id))
speech.df <- data.table(speech=ff.A[[9]]$content, person=ff.A[[9]]$meta$id)
sentences <- data.table(sentSplit(speech.df, "speech"))
sentences <- sentences[, sentence.num := seq(nrow(sentences))]
sentences <- sentences[, tot := NULL]
setcolorder(sentences, c("person", "sentence.num", "speech"))
#syllables per sentence
sentences <- sentences[, syllables := syllable_sum(speech)]
#add cumulative syllable count and percent complete as proxy for progression
sentences <- sentences[, syllables.cumsum := cumsum(syllables)]
sentences <- sentences[, pct.complete := syllables.cumsum / sum(sentences$syllables)]
sentences <- sentences[, pct.complete.100 := pct.complete * 100]
pol.df <- polarity(sentences$speech)$all
sentences <- sentences[, words := pol.df$wc]
sentences <- sentences[, pol := pol.df$polarity]
sentences
#customize and generate plot
my.theme <-
theme(plot.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
axis.text=element_text(size=10),
axis.title=element_text(size=12),
plot.title=element_text(size=16, hjust=0.5))
Plot.setting <- function(gg)
return(gg + geom_point(color="salmon") +
stat_smooth(color="red3", fill="lightgray", size=1.4) +
xlab("Percent complete (by syllable count)") +
scale_x_continuous(labels = percent) + my.theme)
Plot.setting(ggplot(sentences, aes(pct.complete, pol)) +
ylab("Sentiment (sentence-level polarity)") +
ggtitle(ff.A[[9]]$meta$id))
speech.df <- data.table(speech=ff.A[[9]]$content, person=ff.A[[9]]$meta$id)
sentences <- data.table(sentSplit(speech.df, "speech"))
sentences <- sentences[, sentence.num := seq(nrow(sentences))]
sentences <- sentences[, tot := NULL]
setcolorder(sentences, c("person", "sentence.num", "speech"))
#syllables per sentence
sentences <- sentences[, syllables := syllable_sum(speech)]
#add cumulative syllable count and percent complete as proxy for progression
sentences <- sentences[, syllables.cumsum := cumsum(syllables)]
sentences <- sentences[, pct.complete := syllables.cumsum / sum(sentences$syllables)]
sentences <- sentences[, pct.complete.100 := pct.complete * 100]
pol.df <- polarity(sentences$speech)$all
sentences <- sentences[, words := pol.df$wc]
sentences <- sentences[, pol := pol.df$polarity]
sentences
#customize and generate plot
my.theme <-
theme(plot.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
axis.text=element_text(size=10),
axis.title=element_text(size=12),
plot.title=element_text(size=16, hjust=0.5))
Plot.setting <- function(gg)
return(gg + geom_point(color="salmon") +
stat_smooth(color="red3", fill="lightgray", size=1.4) +
xlab("Percent complete (by syllable count)") +
scale_x_continuous(labels = percent) + my.theme)
Plot.setting(ggplot(sentences, aes(pct.complete, pol)) +
ylab("Sentiment (sentence-level polarity)") +
ggtitle(ff.A[[9]]$meta$id))
sentences <- sentences[, readability := scores(automated_readability_index(speech,sentence.num, output = "valid"))$Automated_Readability_Index]
sentences
Plot.setting(ggplot(sentences, aes(pct.complete, readability)) +
ylab("Automated Readability Index") +
ggtitle(ff.A[[9]]$meta$id))
sentences <- sentences[, readability := scores(automated_readability_index(speech,sentence.num, output = "valid"))$Automated_Readability_Index]
sentences
Plot.setting(ggplot(sentences, aes(pct.complete, readability)) +
ylab("Automated Readability Index") +
ggtitle(ff.A[[9]]$meta$id))
#scraping Google search hits
GoogleHits <- function(query){
require(XML)
require(RCurl)
url <- paste0("https://www.google.com/search?q=", gsub(" ", "+", query))
CAINFO = paste0(system.file(package="RCurl"), "/CurlSSL/ca-bundle.crt")
script <- getURL(url, followlocation=T, cainfo=CAINFO)
doc <- htmlParse(script)
res <- xpathSApply(doc, '//*/div[@id="resultStats"]', xmlValue)
return(as.numeric(gsub("[^0-9]", "", res)))
}
##sometimes this chunk may take long time to run or report an error, if this happens then, please just re-open the Rstudio and try again later
#pass each sentence to the function, stripped of punctuation and grouped in brackets, and with “mlk” added to ensure it related to the speech
sentences[, google.hits := GoogleHits(paste0("[", gsub("[,;!.]", "", speech),
"] mlk"))]
sentences
ggplot(sentences, aes(pct.complete, google.hits / 1e6)) +
geom_line(color="red3") + # Lighten dots
xlab("Percent complete (by syllable count)") +
scale_x_continuous(labels = percent) + my.theme +
ylim(0, max(sentences$google.hits) / 1e6) +
ylab("Sentence memorability (millions of Google hits)") +
ggtitle("Memorability")
#scraping Google search hits
GoogleHits <- function(query){
require(XML)
require(RCurl)
url <- paste0("https://www.google.com/search?q=", gsub(" ", "+", query))
CAINFO = paste0(system.file(package="RCurl"), "/CurlSSL/ca-bundle.crt")
script <- getURL(url, followlocation=T, cainfo=CAINFO)
doc <- htmlParse(script)
res <- xpathSApply(doc, '//*/div[@id="resultStats"]', xmlValue)
return(as.numeric(gsub("[^0-9]", "", res)))
}
##sometimes this chunk may take long time to run or report an error, if this happens then, please just re-open the Rstudio and try again later
#pass each sentence to the function, stripped of punctuation and grouped in brackets, and with “mlk” added to ensure it related to the speech
sentences[, google.hits := GoogleHits(paste0("[", gsub("[,;!.]", "", speech),
"] mlk"))]
#scraping Google search hits
GoogleHits <- function(query){
require(XML)
require(RCurl)
url <- paste0("https://www.google.com/search?q=", gsub(" ", "+", query))
CAINFO = paste0(system.file(package="RCurl"), "/CurlSSL/ca-bundle.crt")
script <- getURL(url, followlocation=T, cainfo=CAINFO)
doc <- htmlParse(script)
res <- xpathSApply(doc, '//*/div[@id="resultStats"]', xmlValue)
return(as.numeric(gsub("[^0-9]", "", res)))
}
##sometimes this chunk may take long time to run or report an error, if this happens then, please just re-open the Rstudio and try again later
#pass each sentence to the function, stripped of punctuation and grouped in brackets, and with “mlk” added to ensure it related to the speech
sentences[, google.hits := GoogleHits(paste0("[", gsub("[,;!.]", "", speech),
"] mlk"))]
#scraping Google search hits
GoogleHits <- function(query){
require(XML)
require(RCurl)
url <- paste0("https://www.google.com/search?q=", gsub(" ", "+", query))
CAINFO = paste0(system.file(package="RCurl"), "/CurlSSL/ca-bundle.crt")
script <- getURL(url, followlocation=T, cainfo=CAINFO)
doc <- htmlParse(script)
res <- xpathSApply(doc, '//*/div[@id="resultStats"]', xmlValue)
return(as.integer(gsub("[^0-9]", "", res)))
}
##sometimes this chunk may take long time to run or report an error, if this happens then, please just re-open the Rstudio and try again later
#pass each sentence to the function, stripped of punctuation and grouped in brackets, and with “mlk” added to ensure it related to the speech
sentences[, google.hits := GoogleHits(paste0("[", gsub("[,;!.]", "", speech),
"] mlk"))]
speech.df <- data.table(speech=ff.A[[9]]$content, person=ff.A[[9]]$meta$id)
sentences <- data.table(sentSplit(speech.df, "speech"))
sentences <- sentences[, sentence.num := seq(nrow(sentences))]
sentences <- sentences[, tot := NULL]
setcolorder(sentences, c("person", "sentence.num", "speech"))
#syllables per sentence
sentences <- sentences[, syllables := syllable_sum(speech)]
#add cumulative syllable count and percent complete as proxy for progression
sentences <- sentences[, syllables.cumsum := cumsum(syllables)]
sentences <- sentences[, pct.complete := syllables.cumsum / sum(sentences$syllables)]
sentences <- sentences[, pct.complete.100 := pct.complete * 100]
pol.df <- polarity(sentences$speech)$all
sentences <- sentences[, words := pol.df$wc]
sentences <- sentences[, pol := pol.df$polarity]
sentences
#customize and generate plot
my.theme <-
theme(plot.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
axis.text=element_text(size=10),
axis.title=element_text(size=12),
plot.title=element_text(size=16, hjust=0.5))
Plot.setting <- function(gg)
return(gg + geom_point(color="salmon") +
stat_smooth(color="red3", fill="lightgray", size=1.4) +
xlab("Percent complete (by syllable count)") +
scale_x_continuous(labels = percent) + my.theme)
Plot.setting(ggplot(sentences, aes(pct.complete, pol)) +
ylab("Sentiment (sentence-level polarity)") +
ggtitle(ff.A[[9]]$meta$id))
sentences <- sentences[, readability := scores(automated_readability_index(speech,sentence.num, output = "valid"))$Automated_Readability_Index]
sentences
Plot.setting(ggplot(sentences, aes(pct.complete, readability)) +
ylab("Automated Readability Index") +
ggtitle(ff.A[[9]]$meta$id))
#scraping Google search hits
GoogleHits <- function(query){
require(XML)
require(RCurl)
url <- paste0("https://www.google.com/search?q=", gsub(" ", "+", query))
CAINFO = paste0(system.file(package="RCurl"), "/CurlSSL/ca-bundle.crt")
script <- getURL(url, followlocation=T, cainfo=CAINFO)
doc <- htmlParse(script)
res <- xpathSApply(doc, '//*/div[@id="resultStats"]', xmlValue)
return(as.numeric(gsub("[^0-9]", "", res)))
}
##sometimes this chunk may take long time to run or report an error, if this happens then, please just re-open the Rstudio and try again later
#pass each sentence to the function, stripped of punctuation and grouped in brackets, and with “mlk” added to ensure it related to the speech
sentences[, google.hits := GoogleHits(paste0("[", gsub("[,;!.]", "", speech),
"] mlk"))]
sentences
ggplot(sentences, aes(pct.complete, google.hits / 1e6)) +
geom_line(color="red3") + # Lighten dots
xlab("Percent complete (by syllable count)") +
scale_x_continuous(labels = percent) + my.theme +
ylim(0, max(sentences$google.hits) / 1e6) +
ylab("Sentence memorability (millions of Google hits)") +
ggtitle("Memorability")
#scraping Google search hits
GoogleHits <- function(query){
require(XML)
require(RCurl)
url <- paste0("https://www.google.com/search?q=", gsub(" ", "+", query))
CAINFO = paste0(system.file(package="RCurl"), "/CurlSSL/ca-bundle.crt")
script <- getURL(url, followlocation=T, cainfo=CAINFO)
doc <- htmlParse(script)
res <- xpathSApply(doc, '//*/div[@id="resultStats"]', xmlValue)
return(as.numeric(gsub("[^0-9]", "", res)))
}
packages.used=c("SnowballC", "ggplot2", "rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr", "tm", "syuzhet",
"factoextra", "scales", "RColorBrewer", "RANN", "tm",
"topicmodels","NLP","openNLP","magrittr","wordcloud",
"tidytext","stringr","data.table","shiny","XML","RCurl")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# load packages
library(SnowballC)
library(dplyr)
library(rvest)
library(tibble)
library(qdap)
library(sentimentr)
library(gplots)
library(ggplot2)
library(syuzhet)
library(factoextra)
library(scales)
library(RColorBrewer)
library(RANN)
library(tm)
library(topicmodels)
library(NLP)
library(openNLP)
library(magrittr)
library(wordcloud)
library(tidytext)
library(stringr)
library(shiny)
library(data.table)
library(XML)
library(RCurl)
print(R.version)
##Republican corpus
Rpbl.txt <- file.path("../data/InauguralSpeeches/Republican")
Rpbl <- Corpus(DirSource(Rpbl.txt))
Rpbl
##Democratic corpus
Dmcr.txt <- file.path("../data/InauguralSpeeches/Democratic")
Dmcr <- Corpus(DirSource(Dmcr.txt))
Dmcr
#pre-processing
Rpbl <- tm_map(Rpbl, removePunctuation)
Rpbl <- tm_map(Rpbl, removeNumbers)
Rpbl <- tm_map(Rpbl, tolower)
Rpbl <- tm_map(Rpbl, removeWords, stopwords("english"))
Rpbl <- tm_map(Rpbl, removeWords, c("upon"))
Rpbl <- tm_map(Rpbl, stemDocument)
Rpbl <- tm_map(Rpbl, stripWhitespace)
Rpbl <- tm_map(Rpbl, PlainTextDocument)
tdm.Rpbl <- TermDocumentMatrix(Rpbl)
tdm.tidyRpbl=tidy(tdm.Rpbl)
tdm.overallRpbl=summarise(group_by(tdm.tidyRpbl, term), sum(count))
#generate the wordcloud
wordcloud(tdm.overallRpbl$term, tdm.overallRpbl$`sum(count)`, max.words=70, random.order=FALSE, random.color=FALSE,rot.per=0, colors=brewer.pal(5,"Reds"))
#pre-processing
Dmcr <- tm_map(Dmcr, removePunctuation)
Dmcr <- tm_map(Dmcr, removeNumbers)
Dmcr <- tm_map(Dmcr, tolower)
Dmcr <- tm_map(Dmcr, removeWords, stopwords("english"))
Dmcr <- tm_map(Dmcr, removeWords, c("upon"))
Dmcr <- tm_map(Dmcr, stemDocument)
Dmcr <- tm_map(Dmcr, stripWhitespace)
Dmcr <- tm_map(Dmcr, PlainTextDocument)
tdm.Dmcr <- TermDocumentMatrix(Dmcr)
tdm.tidyDmcr=tidy(tdm.Dmcr)
tdm.overallDmcr=summarise(group_by(tdm.tidyDmcr, term), sum(count))
#generate the wordcloud
wordcloud(tdm.overallDmcr$term, tdm.overallDmcr$`sum(count)`, max.words=70, random.order=FALSE, random.color=FALSE,rot.per=0, colors=brewer.pal(5,"Blues"))
dtm.Rpbl <- DocumentTermMatrix(Rpbl)
freq.Rpbl <- colSums(as.matrix(dtm.Rpbl))
length(freq.Rpbl)
#sort the terms based on frequency in a descending order
ord.Rpbl <- order(freq.Rpbl, decreasing = TRUE)
#view top 30
freq.Rpbl[head(ord.Rpbl, n=30L)]
wf.Rpbl <- data.frame(word=names(freq.Rpbl), freq=freq.Rpbl)
p.Rpbl <- ggplot(subset(wf.Rpbl, freq>76), aes(reorder(word, -freq),freq))
p.Rpbl <- p.Rpbl + geom_bar(stat="identity",fill = "red3")
p.Rpbl <- p.Rpbl + theme(axis.text.x=element_text(angle=45, hjust=1))
p.Rpbl <- p.Rpbl + xlab('Top 30 words') + ylab('Frequency')
p.Rpbl
dtm.Dmcr <- DocumentTermMatrix(Dmcr)
freq.Dmcr <- colSums(as.matrix(dtm.Dmcr))
length(freq.Dmcr)
#sort the terms based on frequency in a descending order
ord.Dmcr <- order(freq.Dmcr, decreasing = TRUE)
#view top 30
freq.Dmcr[head(ord.Dmcr, n=30L)]
wf.Dmcr <- data.frame(word=names(freq.Dmcr), freq=freq.Dmcr)
p.Dmcr <- ggplot(subset(wf.Dmcr, freq>55), aes(reorder(word, -freq),freq))
p.Dmcr <- p.Dmcr + geom_bar(stat="identity",fill = "blue4")
p.Dmcr <- p.Dmcr + theme(axis.text.x=element_text(angle=45, hjust=1))
p.Dmcr <- p.Dmcr + xlab('Top 30 words') + ylab('Frequency')
p.Dmcr
shinyApp(
ui = fluidPage(
titlePanel("Select Frequency Ranges for Parties"),
fluidRow(style = "padding-bottom: 100px;",
column(4, sliderInput('freq1', 'Frequency Range for Republican:',
min = 30, max = 200, value = c(50,100))),
plotOutput('plotR', height = "400px")
),
fluidRow(style = "padding-bottom: 100px;",
column(4, sliderInput('freq2', 'Frequency Range for Democratic:',
min = 30, max = 200, value = c(40,70))),
plotOutput('plotD', height = "400px")
)
),
server = function(input, output){
output$plotR <- renderPlot({
p.Rpbl <- ggplot(subset(wf.Rpbl, freq>min(input$freq1)&freq<max(input$freq1)), aes(reorder(word, -freq),freq))
p.Rpbl <- p.Rpbl + geom_bar(stat="identity",fill = "red3")
p.Rpbl <- p.Rpbl + theme(axis.text.x=element_text(angle=45, hjust=1))
p.Rpbl <- p.Rpbl + xlab('Word') + ylab('Frequency')
p.Rpbl
})
output$plotD <- renderPlot({
p.Dmcr <- ggplot(subset(wf.Dmcr, freq>min(input$freq2)&freq<max(input$freq2)), aes(reorder(word, -freq),freq))
p.Dmcr <- p.Dmcr + geom_bar(stat="identity",fill = "blue4")
p.Dmcr <- p.Dmcr + theme(axis.text.x=element_text(angle=45, hjust=1))
p.Dmcr <- p.Dmcr + xlab('Word') + ylab('Frequency')
p.Dmcr
})
},
options = list(height = 1100)
)
folder.pathA="../data/InauguralSpeeches/All"
speeches.A=list.files(path = folder.pathA, pattern = "*.txt")
ff.A<-Corpus(DirSource(folder.pathA))
speech.df <- data.table(speech=ff.A[[9]]$content, person=ff.A[[9]]$meta$id)
sentences <- data.table(sentSplit(speech.df, "speech"))
sentences <- sentences[, sentence.num := seq(nrow(sentences))]
sentences <- sentences[, tot := NULL]
setcolorder(sentences, c("person", "sentence.num", "speech"))
#syllables per sentence
sentences <- sentences[, syllables := syllable_sum(speech)]
#add cumulative syllable count and percent complete as proxy for progression
sentences <- sentences[, syllables.cumsum := cumsum(syllables)]
sentences <- sentences[, pct.complete := syllables.cumsum / sum(sentences$syllables)]
sentences <- sentences[, pct.complete.100 := pct.complete * 100]
pol.df <- polarity(sentences$speech)$all
sentences <- sentences[, words := pol.df$wc]
sentences <- sentences[, pol := pol.df$polarity]
#customize and generate plot
my.theme <-
theme(plot.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
axis.text=element_text(size=10),
axis.title=element_text(size=12),
plot.title=element_text(size=16, hjust=0.5))
Plot.setting <- function(gg)
return(gg + geom_point(color="salmon") +
stat_smooth(color="red3", fill="lightgray", size=1.4) +
xlab("Percent complete (by syllable count)") +
scale_x_continuous(labels = percent) + my.theme)
Plot.setting(ggplot(sentences, aes(pct.complete, pol)) +
ylab("Sentiment (sentence-level polarity)") +
ggtitle(ff.A[[9]]$meta$id))
sentences <- sentences[, readability := scores(automated_readability_index(speech,sentence.num, output = "valid"))$Automated_Readability_Index]
Plot.setting(ggplot(sentences, aes(pct.complete, readability)) +
ylab("Automated Readability Index") +
ggtitle(ff.A[[9]]$meta$id))
#scraping Google search hits
GoogleHits <- function(query){
require(XML)
require(RCurl)
url <- paste0("https://www.google.com/search?q=", gsub(" ", "+", query))
CAINFO = paste0(system.file(package="RCurl"), "/CurlSSL/ca-bundle.crt")
script <- getURL(url, followlocation=T, cainfo=CAINFO)
doc <- htmlParse(script)
res <- xpathSApply(doc, '//*/div[@id="resultStats"]', xmlValue)
return(as.numeric(gsub("[^0-9]", "", res)))
}
##sometimes this chunk may take long time to run or report an error, if this happens then, please just re-open the Rstudio and try again later
#pass each sentence to the function, stripped of punctuation and grouped in brackets, and with “mlk” added to ensure it related to the speech
sentences[, google.hits := GoogleHits(paste0("[", gsub("[,;!.]", "", speech),
"] mlk"))]
ggplot(sentences, aes(pct.complete, google.hits / 1e6)) +
geom_line(color="red3") + # Lighten dots
xlab("Percent complete (by syllable count)") +
scale_x_continuous(labels = percent) + my.theme +
ylim(0, max(sentences$google.hits) / 1e6) +
ylab("Sentence memorability (millions of Google hits)") +
ggtitle("Memorability")
head(sentences[order(-google.hits)]$speech, 10)
#plotting Google hits on a log scale reduces skew and allows us to work on a ratio scale
sentences <- sentences[, log.google.hits := log(google.hits)]
Plot.setting(ggplot(sentences, aes(pct.complete, log.google.hits)) +
ylab("Memorability (log of sentence's Google hits)") +
ggtitle(ff.A[[9]]$meta$id))
shinyApp(
ui = fluidPage(
titlePanel("Select Speeches"),
fluidRow(style = "padding-bottom: 20px;",
column(4, selectInput('speech1', 'Inaugural Speech',
speeches.A,
selected=speeches.A[1]))
),
fluidRow(style = "padding-bottom: 20px;",
splitLayout(cellWidths = c("33%","33%","33%"),
plotOutput('plot1s', height = "300px"),
plotOutput('plot1r', height = "300px"),
plotOutput('plot1m', height = "300px"))
),
fluidRow(style = "padding-bottom: 20px;",
splitLayout(cellWidths = c("50%","50%"),
plotOutput('plot1ms', height = "300px"),
tableOutput('sord')
)
)
),
server <- function(input, output){
selectData1 <- reactive({
speech.input1 <- ff.A[[input$speech1]]$content
speech.df1 <- data.table(speech=speech.input1, person="DJN")
sentences1 <- data.table(sentSplit(speech.df1, "speech"))
sentences1[, sentence.num := seq(nrow(sentences1))]
sentences1[, tot := NULL]
setcolorder(sentences1, c("person", "sentence.num", "speech"))
# Syllables per sentence
sentences1[, syllables := syllable_sum(speech)]
# Add cumulative syllable count and percent complete as proxy for progression
sentences1[, syllables.cumsum := cumsum(syllables)]
sentences1[, pct.complete := syllables.cumsum / sum(sentences1$syllables)]
sentences1[, pct.complete.100 := pct.complete * 100]
pol.df1 <- polarity(sentences1$speech)$all
sentences1[, words := pol.df$wc]
sentences1[, pol := pol.df$polarity]
sentences1[, readability := scores(automated_readability_index(speech,sentence.num, output = "valid"))$Automated_Readability_Index]
sentences1[, google.hits := GoogleHits(paste0("[", gsub("[,;!.]", "", speech), "] mlk"))]
sentences1[, log.google.hits := log(google.hits)]
})
output$plot1s <- renderPlot({
Plot1.setting <- function(gg)
return(gg + geom_point(color="salmon") +
stat_smooth(color="red3", fill="lightgray", size=1.4) +
xlab("Percent complete (by syllable count)") +
scale_x_continuous(labels = percent) + my.theme)
Plot1.setting(ggplot(selectData1(), aes(pct.complete, pol)) +
ylab("Sentiment (sentence-level polarity)") +
ggtitle("Sentiment"))
})
output$plot1r <- renderPlot({
Plot1.setting <- function(gg)
return(gg + geom_point(color="salmon") +
stat_smooth(color="red3", fill="lightgray", size=1.4) +
xlab("Percent complete (by syllable count)") +
scale_x_continuous(labels = percent) + my.theme)
Plot1.setting(ggplot(selectData1(), aes(pct.complete, readability)) +
ylab("Automated Readability Index") +
ggtitle("Readability"))
})
output$plot1m <- renderPlot({
Plot1.setting <- function(gg)
return(gg + geom_point(color="salmon") +
stat_smooth(color="red3", fill="lightgray", size=1.4) +
xlab("Percent complete (by syllable count)") +
scale_x_continuous(labels = percent) + my.theme)
Plot1.setting(ggplot(selectData1(), aes(pct.complete, log.google.hits)) +
ylab("Memorability (log of sentence's Google hits)") +
ggtitle("Memorability"))
})
output$plot1ms <- renderPlot({
ggplot(selectData1(), aes(pct.complete, google.hits / 1e6)) +
geom_line(color="red3") +
xlab("Percent complete (by syllable count)") +
scale_x_continuous(labels = percent) + my.theme +
ylim(0, max(sentences$google.hits) / 1e6) +
ylab("Sentence memorability (millions of Google hits)") +
ggtitle("Sentence memorability & Top 10 Sentences")
})
output$sord <- renderTable({
head(selectData1()[order(-google.hits)]$speech, 10)
})
},
option = list(height = 1000)
)
